"""
Hybrid Graphiti + PKM Ontology Service

Graphitiì˜ EntityNodeì— PKM ì˜¨í†¨ë¡œì§€ ë ˆì´ë¸”(Topic, Project, Task, Person)ì„
ì¶”ê°€í•˜ì—¬ ë‘ ì‹œìŠ¤í…œì˜ ì¥ì ì„ ê²°í•©:

- Graphiti: Temporal KG, ìë™ ì—”í‹°í‹° ìš”ì•½, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
- PKM Ontology: ìš°ë¦¬ cluster_serviceì™€ í˜¸í™˜ë˜ëŠ” ë ˆì´ë¸”

Flow:
1. Graphitiê°€ ë…¸íŠ¸ë¥¼ ì²˜ë¦¬ â†’ EntityNode ìƒì„±
2. í›„ì²˜ë¦¬ë¡œ EntityNodeì— PKM ë ˆì´ë¸” ì¶”ê°€ (LLM ë¶„ë¥˜)
3. Note â†’ EntityNode MENTIONS ê´€ê³„ ìƒì„±
4. cluster_serviceê°€ PKM ë ˆì´ë¸”ë¡œ í´ëŸ¬ìŠ¤í„°ë§
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import asyncio

from app.db.neo4j import get_neo4j_client
from app.config import settings

logger = logging.getLogger(__name__)

# PKM ì˜¨í†¨ë¡œì§€ íƒ€ì…
PKM_TYPES = ["Topic", "Project", "Task", "Person"]

# ì—”í‹°í‹° ì´ë¦„ ê¸°ë°˜ ë¶„ë¥˜ ê·œì¹™ (LLM í˜¸ì¶œ ì—†ì´ ë¹ ë¥¸ ë¶„ë¥˜)
# ë” ì •êµí•œ ë¶„ë¥˜ê°€ í•„ìš”í•˜ë©´ LLM ì‚¬ìš©
CLASSIFICATION_RULES = {
    "Person": [
        # ì‚¬ëŒ ì´ë¦„ íŒ¨í„´
        lambda name: any(suffix in name for suffix in ["ë‹˜", "ì”¨", "êµìˆ˜", "ë°•ì‚¬", "ì„ ìƒ"]),
        lambda name: name.endswith(("ìˆ˜", "í˜¸", "ë¯¼", "ì¤€", "ì§„", "í˜„", "ì„", "ì˜", "í›ˆ")),  # í•œêµ­ ì´ë¦„ ëê¸€ì
    ],
    "Project": [
        lambda name: any(kw in name.lower() for kw in ["í”„ë¡œì íŠ¸", "project", "ê°œë°œ", "êµ¬í˜„", "ì‹œìŠ¤í…œ"]),
        lambda name: name.startswith(("PKM", "Didymos", "AI")),
    ],
    "Task": [
        lambda name: any(kw in name.lower() for kw in ["todo", "task", "ì‘ì—…", "í• ì¼", "ìˆ˜ì •", "ì¶”ê°€", "êµ¬í˜„í•´ì•¼"]),
    ],
    # Topicì€ ê¸°ë³¸ê°’ (ë‹¤ë¥¸ íƒ€ì…ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ Topic)
}


def classify_entity_to_pkm_type(entity_name: str, entity_summary: str = None) -> str:
    """
    ì—”í‹°í‹° ì´ë¦„/ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ PKM íƒ€ì… ë¶„ë¥˜

    Args:
        entity_name: ì—”í‹°í‹° ì´ë¦„
        entity_summary: Graphitiê°€ ìƒì„±í•œ ì—”í‹°í‹° ìš”ì•½

    Returns:
        PKM íƒ€ì… (Topic, Project, Task, Person)
    """
    name_lower = entity_name.lower()

    # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜
    for pkm_type, rules in CLASSIFICATION_RULES.items():
        for rule in rules:
            try:
                if rule(entity_name):
                    return pkm_type
            except Exception:
                continue

    # ìš”ì•½ì—ì„œ íŒíŠ¸ ì°¾ê¸°
    if entity_summary:
        summary_lower = entity_summary.lower()
        if any(kw in summary_lower for kw in ["ì‚¬ëŒ", "person", "ì—°êµ¬ì›", "í•™ìƒ", "íŒ€ì›"]):
            return "Person"
        if any(kw in summary_lower for kw in ["í”„ë¡œì íŠ¸", "project", "ê°œë°œ ì¤‘", "êµ¬í˜„"]):
            return "Project"
        if any(kw in summary_lower for kw in ["í•´ì•¼ í• ", "ì™„ë£Œí•´ì•¼", "task", "todo"]):
            return "Task"

    # ê¸°ë³¸ê°’: Topic
    return "Topic"


async def add_pkm_labels_to_graphiti_entities(
    vault_id: str = None,
    batch_size: int = 100
) -> Dict[str, Any]:
    """
    ê¸°ì¡´ Graphiti EntityNodeì— PKM ë ˆì´ë¸” ì¶”ê°€

    ì´ë¯¸ ë ˆì´ë¸”ì´ ìˆëŠ” ì—”í‹°í‹°ëŠ” ìŠ¤í‚µ

    Args:
        vault_id: íŠ¹ì • vaultë§Œ ì²˜ë¦¬ (Noneì´ë©´ ì „ì²´)
        batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ì—”í‹°í‹° ìˆ˜

    Returns:
        ì²˜ë¦¬ ê²°ê³¼ í†µê³„
    """
    client = get_neo4j_client()

    try:
        # Step 1: PKM ë ˆì´ë¸”ì´ ì—†ëŠ” EntityNode ì¡°íšŒ
        cypher_find = """
        MATCH (e:EntityNode)
        WHERE NOT e:Topic AND NOT e:Project AND NOT e:Task AND NOT e:Person
        RETURN e.uuid as uuid, e.name as name, e.summary as summary
        LIMIT $batch_size
        """

        entities = client.query(cypher_find, {"batch_size": batch_size})

        if not entities:
            logger.info("No EntityNode without PKM labels found")
            return {
                "status": "completed",
                "processed": 0,
                "message": "All EntityNodes already have PKM labels"
            }

        logger.info(f"Found {len(entities)} EntityNodes to classify")

        # Step 2: ê° ì—”í‹°í‹° ë¶„ë¥˜ ë° ë ˆì´ë¸” ì¶”ê°€
        stats = {"Topic": 0, "Project": 0, "Task": 0, "Person": 0, "errors": 0}

        for entity in entities:
            try:
                uuid = entity["uuid"]
                name = entity["name"] or uuid
                summary = entity.get("summary", "")

                # PKM íƒ€ì… ë¶„ë¥˜
                pkm_type = classify_entity_to_pkm_type(name, summary)

                # ë ˆì´ë¸” ì¶”ê°€
                cypher_add_label = f"""
                MATCH (e:EntityNode {{uuid: $uuid}})
                SET e:{pkm_type}
                SET e.pkm_type = $pkm_type
                SET e.pkm_classified_at = datetime()
                RETURN e.name as name
                """

                result = client.query(cypher_add_label, {"uuid": uuid, "pkm_type": pkm_type})

                if result:
                    stats[pkm_type] += 1
                    logger.debug(f"Added {pkm_type} label to: {name}")

            except Exception as e:
                logger.error(f"Error adding label to {entity.get('name')}: {e}")
                stats["errors"] += 1

        total_processed = sum(stats[t] for t in PKM_TYPES)
        logger.info(f"âœ… PKM labels added: {stats}")

        return {
            "status": "success",
            "processed": total_processed,
            "stats": stats,
            "remaining": await _count_unlabeled_entities(client)
        }

    except Exception as e:
        logger.error(f"Error in add_pkm_labels_to_graphiti_entities: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


async def _count_unlabeled_entities(client) -> int:
    """PKM ë ˆì´ë¸”ì´ ì—†ëŠ” EntityNode ìˆ˜ ì¡°íšŒ"""
    try:
        result = client.query("""
            MATCH (e:EntityNode)
            WHERE NOT e:Topic AND NOT e:Project AND NOT e:Task AND NOT e:Person
            RETURN count(e) as count
        """, {})
        return result[0]["count"] if result else 0
    except Exception:
        return -1


async def create_mentions_from_episodes(
    vault_id: str = None,
    batch_size: int = 100
) -> Dict[str, Any]:
    """
    Graphiti Episode-Entity ê´€ê³„ë¥¼ Note-Entity MENTIONS ê´€ê³„ë¡œ ë³€í™˜

    GraphitiëŠ” Episode â†’ EntityNode ê´€ê³„ë¥¼ ì‚¬ìš©
    cluster_serviceëŠ” Note â†’ Entity MENTIONS ê´€ê³„ë¥¼ ê¸°ëŒ€

    ì´ í•¨ìˆ˜ëŠ” Episodeì˜ source_descriptionì—ì„œ note_idë¥¼ ì¶”ì¶œí•˜ì—¬
    Note â†’ EntityNode MENTIONS ê´€ê³„ë¥¼ ìƒì„±

    Args:
        vault_id: íŠ¹ì • vaultë§Œ ì²˜ë¦¬
        batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ê´€ê³„ ìˆ˜

    Returns:
        ì²˜ë¦¬ ê²°ê³¼ í†µê³„
    """
    client = get_neo4j_client()

    try:
        # Step 1: Episode-Entity ê´€ê³„ì—ì„œ Note-Entity MENTIONSê°€ ì—†ëŠ” ê²ƒ ì°¾ê¸°
        # Graphitiì˜ Episodeì—ëŠ” source_descriptionì— "Obsidian note: {path}" í˜•íƒœë¡œ ì €ì¥ë¨
        cypher_find = """
        MATCH (ep:EpisodicNode)-[:MENTIONS]->(e:EntityNode)
        WHERE ep.source_description STARTS WITH 'Obsidian note:'
        WITH ep, e,
             replace(ep.source_description, 'Obsidian note: ', '') as note_path
        MATCH (n:Note {note_id: note_path})
        WHERE NOT (n)-[:MENTIONS]->(e)
        RETURN n.note_id as note_id, e.uuid as entity_uuid, e.name as entity_name
        LIMIT $batch_size
        """

        relations = client.query(cypher_find, {"batch_size": batch_size})

        if not relations:
            logger.info("No new MENTIONS relationships to create")
            return {
                "status": "completed",
                "created": 0,
                "message": "All Episode-Entity relations already have MENTIONS"
            }

        logger.info(f"Found {len(relations)} MENTIONS relationships to create")

        # Step 2: MENTIONS ê´€ê³„ ìƒì„±
        created = 0
        errors = 0

        for rel in relations:
            try:
                cypher_create = """
                MATCH (n:Note {note_id: $note_id})
                MATCH (e:EntityNode {uuid: $entity_uuid})
                MERGE (n)-[m:MENTIONS]->(e)
                SET m.created_at = datetime()
                SET m.source = 'graphiti_migration'
                RETURN count(m) as count
                """

                result = client.query(cypher_create, {
                    "note_id": rel["note_id"],
                    "entity_uuid": rel["entity_uuid"]
                })

                if result and result[0]["count"] > 0:
                    created += 1

            except Exception as e:
                logger.error(f"Error creating MENTIONS: {e}")
                errors += 1

        logger.info(f"âœ… Created {created} MENTIONS relationships")

        return {
            "status": "success",
            "created": created,
            "errors": errors
        }

    except Exception as e:
        logger.error(f"Error in create_mentions_from_episodes: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


async def migrate_graphiti_to_hybrid(
    vault_id: str = None,
    max_iterations: int = 10
) -> Dict[str, Any]:
    """
    ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜: Graphiti ìŠ¤í‚¤ë§ˆ â†’ í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í‚¤ë§ˆ

    1. EntityNodeì— PKM ë ˆì´ë¸” ì¶”ê°€
    2. Episode-Entity â†’ Note-Entity MENTIONS ê´€ê³„ ìƒì„±

    Args:
        vault_id: íŠ¹ì • vaultë§Œ ì²˜ë¦¬
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ë°°ì¹˜ ì²˜ë¦¬)

    Returns:
        ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼
    """
    logger.info(f"ğŸš€ Starting Graphiti â†’ Hybrid migration (vault: {vault_id or 'all'})")

    results = {
        "pkm_labels": {"total_processed": 0, "stats": {}},
        "mentions": {"total_created": 0},
        "iterations": 0
    }

    for i in range(max_iterations):
        results["iterations"] = i + 1

        # Step 1: PKM ë ˆì´ë¸” ì¶”ê°€
        label_result = await add_pkm_labels_to_graphiti_entities(vault_id)

        if label_result.get("processed", 0) > 0:
            results["pkm_labels"]["total_processed"] += label_result["processed"]
            for pkm_type in PKM_TYPES:
                prev = results["pkm_labels"]["stats"].get(pkm_type, 0)
                results["pkm_labels"]["stats"][pkm_type] = prev + label_result.get("stats", {}).get(pkm_type, 0)

        # Step 2: MENTIONS ê´€ê³„ ìƒì„±
        mentions_result = await create_mentions_from_episodes(vault_id)

        if mentions_result.get("created", 0) > 0:
            results["mentions"]["total_created"] += mentions_result["created"]

        # ë” ì´ìƒ ì²˜ë¦¬í•  ê²ƒì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if label_result.get("processed", 0) == 0 and mentions_result.get("created", 0) == 0:
            logger.info(f"Migration completed after {i + 1} iterations")
            break

        # Rate limiting
        await asyncio.sleep(0.5)

    logger.info(f"âœ… Migration complete: {results}")
    return results


async def process_note_hybrid(
    note_id: str,
    content: str,
    updated_at: datetime = None,
    metadata: dict = None
) -> Dict[str, Any]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ë…¸íŠ¸ ì²˜ë¦¬

    1. Graphitië¡œ ì—”í‹°í‹° ì¶”ì¶œ (temporal, ìë™ ìš”ì•½)
    2. ì¶”ì¶œëœ EntityNodeì— PKM ë ˆì´ë¸” ì¶”ê°€
    3. Note â†’ EntityNode MENTIONS ê´€ê³„ ìƒì„±

    Args:
        note_id: ë…¸íŠ¸ ID
        content: ë…¸íŠ¸ ë‚´ìš©
        updated_at: ìˆ˜ì • ì‹œê°„
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    from app.services.graphiti_service import async_process_note

    try:
        # Step 1: Graphitië¡œ ì²˜ë¦¬
        graphiti_result = await async_process_note(
            note_id=note_id,
            content=content,
            updated_at=updated_at,
            metadata=metadata
        )

        if graphiti_result.get("status") != "success":
            return graphiti_result

        nodes_extracted = graphiti_result.get("nodes_extracted", 0)

        if nodes_extracted == 0:
            return graphiti_result

        # Step 2: ì¶”ì¶œëœ EntityNodeì— PKM ë ˆì´ë¸” ì¶”ê°€
        client = get_neo4j_client()

        # ì´ ë…¸íŠ¸ì™€ ì—°ê²°ëœ EntityNode ì°¾ê¸°
        cypher_find_entities = """
        MATCH (ep:EpisodicNode)-[:MENTIONS]->(e:EntityNode)
        WHERE ep.name = $episode_name
          AND NOT e:Topic AND NOT e:Project AND NOT e:Task AND NOT e:Person
        RETURN e.uuid as uuid, e.name as name, e.summary as summary
        """

        episode_name = f"note_{note_id}"
        entities = client.query(cypher_find_entities, {"episode_name": episode_name})

        labeled_count = 0
        for entity in (entities or []):
            pkm_type = classify_entity_to_pkm_type(
                entity["name"] or entity["uuid"],
                entity.get("summary", "")
            )

            cypher_add_label = f"""
            MATCH (e:EntityNode {{uuid: $uuid}})
            SET e:{pkm_type}
            SET e.pkm_type = $pkm_type
            SET e.pkm_classified_at = datetime()
            """

            client.query(cypher_add_label, {"uuid": entity["uuid"], "pkm_type": pkm_type})
            labeled_count += 1

        # Step 3: Note â†’ EntityNode MENTIONS ê´€ê³„ ìƒì„±
        cypher_create_mentions = """
        MATCH (n:Note {note_id: $note_id})
        MATCH (ep:EpisodicNode {name: $episode_name})-[:MENTIONS]->(e:EntityNode)
        WHERE NOT (n)-[:MENTIONS]->(e)
        MERGE (n)-[m:MENTIONS]->(e)
        SET m.created_at = datetime()
        SET m.source = 'graphiti_hybrid'
        RETURN count(m) as count
        """

        mentions_result = client.query(cypher_create_mentions, {
            "note_id": note_id,
            "episode_name": episode_name
        })

        mentions_created = mentions_result[0]["count"] if mentions_result else 0

        return {
            **graphiti_result,
            "pkm_labels_added": labeled_count,
            "mentions_created": mentions_created,
            "hybrid_mode": True
        }

    except Exception as e:
        logger.error(f"Error in hybrid processing for {note_id}: {e}")
        return {
            "status": "error",
            "note_id": note_id,
            "error": str(e)
        }


# Sync wrapper for compatibility
def process_note_to_graph_hybrid(note_id: str, content: str, metadata: dict = None) -> int:
    """
    ë™ê¸° ë˜í¼: ê¸°ì¡´ ontology_serviceì™€ í˜¸í™˜
    """
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    asyncio.run,
                    process_note_hybrid(note_id, content, metadata=metadata)
                )
                result = future.result()
        else:
            result = loop.run_until_complete(
                process_note_hybrid(note_id, content, metadata=metadata)
            )

        return result.get("nodes_extracted", 0)

    except RuntimeError:
        result = asyncio.run(process_note_hybrid(note_id, content, metadata=metadata))
        return result.get("nodes_extracted", 0)
