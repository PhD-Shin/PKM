"""
Notes API ë¼ìš°í„°
"""
from fastapi import APIRouter, HTTPException, status, Query, BackgroundTasks
from app.schemas.note import NoteSyncRequest, NoteSyncResponse
from app.schemas.context import NoteContextResponse
from app.db.neo4j import get_neo4j_client
from app.services.graph_service import upsert_note, get_note, get_all_notes
from app.services.graph_visualization_service import get_note_graph_vis
from app.services.ontology_service import process_note_to_graph
from app.services.context_service import get_note_context
from app.services.llm_client import summarize_content
from app.utils.cache import TTLCache
from app.utils.auth import get_user_id_from_token
from app.config import settings
from datetime import datetime
import logging
import asyncio

logger = logging.getLogger(__name__)

# Feature flag for Graphiti (controlled via settings or env)
USE_GRAPHITI = getattr(settings, 'use_graphiti', False)

# Rate limiting: ë™ì‹œ AI ì²˜ë¦¬ ì œí•œ (OpenAI Rate Limit ë°©ì§€)
_ai_semaphore = asyncio.Semaphore(2)  # ìµœëŒ€ 2ê°œ ë™ì‹œ ì²˜ë¦¬
_AI_PROCESSING_DELAY = 1.0  # ì²˜ë¦¬ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

router = APIRouter(prefix="/notes", tags=["notes"])
context_cache = TTLCache(ttl_seconds=300)  # 5ë¶„ìœ¼ë¡œ ì—°ì¥
graph_cache = TTLCache(ttl_seconds=300)  # 5ë¶„ìœ¼ë¡œ ì—°ì¥


async def process_ai_in_background(
    note_id: str,
    content: str,
    tags: list,
    path: str,
    title: str,
    created_at: str,
    updated_at: str
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ AI ì²˜ë¦¬ (ì—”í‹°í‹° ì¶”ì¶œ + ì„ë² ë”© ìƒì„±)
    API ì‘ë‹µì„ ë¹ ë¥´ê²Œ ë°˜í™˜í•˜ê³  AI ì‘ì—…ì€ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (OpenAI Rate Limit ë°©ì§€)
    """
    async with _ai_semaphore:
        # Rate limiting: ì²˜ë¦¬ ê°„ ëŒ€ê¸° ì‹œê°„
        await asyncio.sleep(_AI_PROCESSING_DELAY)

        try:
            logger.info(f"ğŸ”„ Background AI processing started for: {note_id[:50]}...")

            # 1. ì—”í‹°í‹° ì¶”ì¶œ (Hybrid Mode: Graphiti + PKM Labels)
            if USE_GRAPHITI:
                # Hybrid mode: Graphiti extracts EntityNode, then add PKM labels
                from app.services.hybrid_graphiti_service import process_note_hybrid
                note_updated_at = datetime.now()
                if updated_at:
                    try:
                        updated_str = updated_at.replace('Z', '+00:00')
                        note_updated_at = datetime.fromisoformat(updated_str)
                    except (ValueError, AttributeError):
                        pass

                hybrid_result = await process_note_hybrid(
                    note_id=note_id,
                    content=content,
                    updated_at=note_updated_at,
                    metadata={
                        "tags": tags,
                        "path": path,
                        "title": title,
                        "created_at": created_at
                    }
                )
                extracted_nodes = hybrid_result.get("nodes_extracted", 0)
                pkm_labels = hybrid_result.get("pkm_labels_added", 0)
                mentions = hybrid_result.get("mentions_created", 0)
                logger.info(f"âœ… Hybrid mode: {extracted_nodes} entities, {pkm_labels} PKM labels, {mentions} MENTIONS")
            else:
                extracted_nodes = process_note_to_graph(
                    note_id=note_id,
                    content=content,
                    metadata={"tags": tags}
                )
                logger.info(f"âœ… Extracted {extracted_nodes} entities from note")

            # 2. ì„ë² ë”© ìƒì„± ë° ì €ì¥
            from app.services.vector_service import store_note_embedding
            embedding_created = store_note_embedding(
                note_id=note_id,
                content=content,
                metadata={"tags": tags}
            )

            if embedding_created:
                logger.info(f"âœ… Embedding created for note: {note_id[:50]}")

            # ìºì‹œ ë¬´íš¨í™”
            context_cache.clear(note_id)
            graph_cache.clear_prefix(f"{note_id}:")

        except Exception as e:
            logger.error(f"âŒ Background AI processing failed for {note_id[:50]}: {e}", exc_info=True)


@router.post("/sync", response_model=NoteSyncResponse)
async def sync_note(payload: NoteSyncRequest, background_tasks: BackgroundTasks):
    """
    ë…¸íŠ¸ ë™ê¸°í™” API

    User, Vault, Note ë…¸ë“œë¥¼ Neo4jì— ìƒì„±/ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    AI ì²˜ë¦¬(ì—”í‹°í‹° ì¶”ì¶œ + ì„ë² ë”©)ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
    """
    try:
        client = get_neo4j_client()
        user_id = get_user_id_from_token(payload.user_token)

        success = upsert_note(
            client=client,
            user_id=user_id,
            vault_id=payload.vault_id,
            note_data=payload.note.model_dump(exclude_none=True),
        )

        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to save note",
            )

        # AI ì²˜ë¦¬ë¥¼ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰ (contentê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        content_for_ai = payload.note.content or ""
        if payload.privacy_mode == "summary":
            content_for_ai = summarize_content(content_for_ai)
        elif payload.privacy_mode == "metadata":
            content_for_ai = ""

        ai_scheduled = False
        if content_for_ai:
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ AI ì²˜ë¦¬ ì‹¤í–‰ (APIëŠ” ì¦‰ì‹œ ì‘ë‹µ)
            background_tasks.add_task(
                process_ai_in_background,
                note_id=payload.note.note_id,
                content=content_for_ai,
                tags=payload.note.tags or [],
                path=payload.note.path or "",
                title=payload.note.title or "",
                created_at=payload.note.created_at or "",
                updated_at=payload.note.updated_at or ""
            )
            ai_scheduled = True
            logger.info(f"ğŸ“‹ AI processing scheduled for: {payload.note.note_id[:50]}...")

        message = "Note synced successfully"
        if ai_scheduled:
            message += ". AI processing scheduled in background."

        return NoteSyncResponse(
            status="success",
            note_id=payload.note.note_id,
            message=message,
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )


@router.get("/get/{note_id}")
async def get_note_by_id(note_id: str):
    """
    ë…¸íŠ¸ IDë¡œ ë…¸íŠ¸ ì¡°íšŒ
    """
    client = get_neo4j_client()
    note = get_note(client, note_id)

    if not note:
        raise HTTPException(status_code=404, detail="Note not found")

    return note


@router.get("/list/{user_token}/{vault_id}")
async def list_notes(
    user_token: str,
    vault_id: str,
    limit: int = Query(50, ge=1, le=500, description="ë…¸íŠ¸ ìˆ˜ ì œí•œ"),
    offset: int = Query(0, ge=0, description="ì‹œì‘ ìœ„ì¹˜")
):
    """
    íŠ¹ì • Vaultì˜ ë…¸íŠ¸ ëª©ë¡ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜)

    Args:
        limit: ë°˜í™˜í•  ë…¸íŠ¸ ìˆ˜ (ê¸°ë³¸ 50, ìµœëŒ€ 500)
        offset: ì‹œì‘ ì¸ë±ìŠ¤ (í˜ì´ì§€ë„¤ì´ì…˜ìš©)
    """
    client = get_neo4j_client()
    user_id = get_user_id_from_token(user_token)

    # ì „ì²´ ë…¸íŠ¸ ì¡°íšŒ í›„ ìŠ¬ë¼ì´ì‹± (ì¶”í›„ DB ë ˆë²¨ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
    all_notes = get_all_notes(client, user_id, vault_id)
    paginated_notes = all_notes[offset:offset + limit]

    return {
        "user_id": user_id,
        "vault_id": vault_id,
        "total": len(all_notes),
        "count": len(paginated_notes),
        "limit": limit,
        "offset": offset,
        "notes": paginated_notes
    }


@router.get("/context/{note_id:path}", response_model=NoteContextResponse)
async def get_context(note_id: str, user_token: str):
    """
    ë…¸íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ (í† í”½/í”„ë¡œì íŠ¸/íƒœìŠ¤í¬ + ì¶”ì²œ ë…¸íŠ¸)
    """
    try:
        cached = context_cache.get(note_id)
        if cached:
            return cached

        context = get_note_context(note_id=note_id, content_preview=note_id)
        context_obj = NoteContextResponse(**context)
        context_cache.set(note_id, context_obj)
        return context_obj
    except Exception as e:
        logger.error(f"Failed to get context for note {note_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to get note context"
        )


@router.get("/graph/{note_id:path}")
async def get_note_graph(note_id: str, user_token: str, hops: int = 1):
    """
    ë…¸íŠ¸ ê·¸ë˜í”„ ì¡°íšŒ (vis-network í˜•ì‹)
    """
    try:
        cache_key = f"{note_id}:{hops}"
        cached = graph_cache.get(cache_key)
        if cached:
            return cached

        graph = get_note_graph_vis(note_id=note_id, hops=hops)
        graph_cache.set(cache_key, graph)
        return graph
    except Exception as e:
        logger.error(f"Failed to get graph for note {note_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to get note graph"
        )
